{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "080af79b-f58f-4249-8ada-9c9cf0f45aa6",
   "metadata": {},
   "source": [
    "# Mini Czech Benchmark\n",
    "\n",
    "This notebook evaluates models by running a text generation pipeline over four datasets: `agree`, `czech_news`, `klokanek` and `ctkfacts`, either *full* data or *mini* (random 200 rows) or *tiny* ([selected](https://arxiv.org/abs/2402.14992) 100 rows).\n",
    "\n",
    "It can be run through [paperpile](https://github.com/nteract/papermill) as follows:\n",
    "\n",
    "```\n",
    "  model=\"meta-llama/Llama-3.2-1B-Instruct\"  # or other HuggingFace model\n",
    "  hf_token=\"** Your HuggingFace read access token **\"\n",
    "  papermill minicz_bench.ipynb output.ipynb -p MODEL \"$model\" -p HF_TOKEN \"$hf_token\" -p DATA_SIZE \"mini\" -p OUTPUT_DIR \"\" -k python3\n",
    "```\n",
    "\n",
    "[MiniCzechBenchmark](https://github.com/simecek/MiniCzechBenchmark) is a small subset selected from [CzechBench](https://gitlab.com/jirkoada/czech-bench) benchmark suited for fast model assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7bde11-8c7c-4fec-93c7-117f8743976a",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# papermill parameters\n",
    "\n",
    "MODEL = 'mistralai/Mistral-7B-Instruct-v0.3' # hf hub model, e.g. mistralai/Mistral-7B-Instruct-v0.3\n",
    "\n",
    "MESSAGES  = 'simplemessages' # Choose one of: 'simplemessages' or 'justprompt' or 'useronly'\n",
    "\n",
    "DATA_SIZE = 'mini' # Choose one of: 'full' or 'mini' or 'tiny'\n",
    "\n",
    "OUTPUT_DIR = 'bench_runs'  # folder to export metrics and outputs (None or '' to avoid saving)\n",
    "\n",
    "PIPELINE_TYPE = 'noSampling'  # type of text-generation pipeline; currently only 'noSampling' supported\n",
    "\n",
    "HF_TOKEN = ''  # HF token needed to access gated models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc236d33-d4e7-4268-9e4e-bc192331cdb1",
   "metadata": {},
   "source": [
    "## Text-generation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe84ff-420c-458f-93d1-384171f67c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edce86dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitsandbytes\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "MAX_NEW_TOKENS = {\n",
    "    'agree': 2,\n",
    "    'czech_news': 2,\n",
    "    'klokanek': 2,\n",
    "    'ctkfacts': 2\n",
    "}\n",
    "\n",
    "def message_function(message_strategy, user_prompts, system_prompts):\n",
    "    if message_strategy == 'simplemessages':\n",
    "        messages = [[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ] for system_prompt, user_prompt  in zip(system_prompts, user_prompts)]\n",
    "    elif message_strategy == 'justprompt':\n",
    "        messages = [f\"{system_prompt}\\n\\n{user_prompt}\" for system_prompt, user_prompt in zip(system_prompts, user_prompts)]\n",
    "    elif message_strategy == 'useronly':\n",
    "        messages = [[\n",
    "            {\"role\": \"user\", \"content\": f\"{system_prompt}\\n\\n{user_prompt}\"},\n",
    "        ] for system_prompt, user_prompt  in zip(system_prompts, user_prompts)]\n",
    "    else:\n",
    "        raise('Message strategy not implemeted')\n",
    "        \n",
    "    return messages\n",
    "\n",
    "def cleaning_function(raw_outputs):\n",
    "    return [x[0]['generated_text'][:3].strip().replace(\")\", \"\").replace(\".\", \"\") for x in raw_outputs]\n",
    "\n",
    "if DATA_SIZE == \"full\":\n",
    "    DATASETS = {\n",
    "        'agree': 'simecek/small_agree',\n",
    "        'czech_news': 'simecek/small_czech_news',\n",
    "        'klokanek': 'simecek/small_klokanek',\n",
    "        'ctkfacts': 'simecek/small_ctkfacts'}\n",
    "elif  DATA_SIZE == \"mini\":\n",
    "    DATASETS = {\n",
    "        'agree': 'simecek/mini_agree',\n",
    "        'czech_news': 'simecek/mini_czech_news',\n",
    "        'klokanek': 'simecek/mini_klokanek',\n",
    "        'ctkfacts': 'simecek/mini_ctkfacts'}\n",
    "elif  DATA_SIZE == \"tiny\":\n",
    "    raise(f\"Data size {DATA_SIZE} not implemeted\")\n",
    "else:\n",
    "    raise(f\"Data size {DATA_SIZE} not implemeted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99040a4-8b0d-4e9e-941b-a141fd269805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=MODEL, \n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16}, \n",
    "    device_map=\"auto\",\n",
    "    do_sample=False,\n",
    "    temperature=0,\n",
    "    pad_token_id=2  # TODO: Instead of hard-coded value, find better way to set pad_token_id to eos_token_id \n",
    ")\n",
    "\n",
    "# Explicitly set pad_token_id to eos_token_id to prevent the warning\n",
    "pipe.model.config.pad_token_id = pipe.model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1361171-13cc-4c0d-93d8-a0bb0d39b1cc",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68c9eaf-bb52-4a48-a2dc-3bdf3c27f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_outputs = {}  # raw outputs from llm\n",
    "clean_outputs = {}  # after cleaning\n",
    "dfs = {}  # dataframe comparing clean_outputs to correct answers\n",
    "metrics = {}  # overall summaries for each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710e1147-876e-4722-9f11-153f33033f0d",
   "metadata": {},
   "source": [
    "### AGREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65054088-c1f7-41f6-a109-e426db8028ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'agree'\n",
    "\n",
    "dt = load_dataset(DATASETS[dataset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f9b67d-81d6-4f1d-ba49-16d2009cac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = message_function(MESSAGES, dt['train']['user_prompt'], dt['train']['system_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d856af0-3968-42ec-9373-96779559a5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pipe(messages[:5], return_full_text=False, max_new_tokens=MAX_NEW_TOKENS[dataset_name])\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fbb407-6827-4a4b-86bd-9219a684a22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_outputs[dataset_name] = pipe(messages, return_full_text=False, max_new_tokens=MAX_NEW_TOKENS[dataset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5be339-050d-4cc8-98fa-bcd8bf5d363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_outputs[dataset_name] = cleaning_function(raw_outputs[dataset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4b0cb8-58e3-4201-8000-aa382068bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[dataset_name] = pd.DataFrame({\n",
    "    'correct_answer_minus_1': dt['train']['answer_idx'],\n",
    "    'answer': clean_outputs[dataset_name],\n",
    "})\n",
    "\n",
    "dfs[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f7237-7e2f-4452-9435-7b5c3e74c9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[dataset_name]['valid'] = dfs[dataset_name].answer.isin(['1', '2', '3', '4', '5'])\n",
    "dfs[dataset_name]['correct'] = [(x in ['1', '2', '3', '4', '5']) and int(x) == int(y)+1 for x,y in zip(dfs[dataset_name].answer, dfs[dataset_name].correct_answer_minus_1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c298c1b8-1442-403d-bf33-aab782b0dfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct answers vs valid answers\n",
    "metrics[dataset_name] = (dfs[dataset_name]['valid'].mean().item(), dfs[dataset_name].correct.mean().item())\n",
    "metrics[dataset_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ef058c-f03d-4acb-9b82-2316268cddac",
   "metadata": {},
   "source": [
    "### CZECH NEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fac7dde-7066-459a-9c64-11197d308af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'czech_news'\n",
    "\n",
    "dt = load_dataset(DATASETS[dataset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd589ce-157d-41bf-b3c0-788f38ed5d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = message_function(MESSAGES, dt['train']['user_prompt'], dt['train']['system_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1838e5-3c54-430b-9e8a-a369e5824017",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pipe(messages[:5], return_full_text=False, max_new_tokens=MAX_NEW_TOKENS[dataset_name])\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dd3598-5f1f-4255-a9c2-91d1dc892a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_outputs[dataset_name] = pipe(messages, return_full_text=False, max_new_tokens=MAX_NEW_TOKENS[dataset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb17bb36-e041-4e49-b1e9-ca0c19f83330",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_outputs[dataset_name] = cleaning_function(raw_outputs[dataset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5ccbf4-f7b6-423b-8e4d-0857b48b9c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[dataset_name] = pd.DataFrame({\n",
    "    'correct_answer': dt['train']['category'],\n",
    "    'answer': clean_outputs[dataset_name],\n",
    "})\n",
    "\n",
    "dfs[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb4117f-74f0-47b2-aad5-fc2c1162b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[dataset_name]['valid'] = dfs[dataset_name].answer.isin(['1', '2', '3', '4', '5'])\n",
    "dfs[dataset_name]['correct'] = dfs[dataset_name].answer.apply(str) == dfs[dataset_name].correct_answer.apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c2e511-d71b-4107-9db4-8f7406ef012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct answers vs valid answers\n",
    "metrics[dataset_name] = (dfs[dataset_name]['valid'].mean().item(), dfs[dataset_name].correct.mean().item())\n",
    "metrics[dataset_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505f3ea0-ce92-4331-92fd-be92838e0f9b",
   "metadata": {},
   "source": [
    "### KLOKANEK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6746ba-425f-4259-b52d-ced6cebafc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'klokanek'\n",
    "\n",
    "dt = load_dataset(DATASETS[dataset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ed9bad-99af-4873-84bb-5a2cc7ea8f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = message_function(MESSAGES, dt['train']['user_prompt'], dt['train']['system_prompt'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd102cd-304b-4354-b249-edc7734e31f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pipe(messages[:5], return_full_text=False, max_new_tokens=MAX_NEW_TOKENS[dataset_name])\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bc7d22-1517-478a-bd24-7dbc539ebe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_outputs[dataset_name] = pipe(messages, return_full_text=False, max_new_tokens=MAX_NEW_TOKENS[dataset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d78f3e-3dac-4a13-b182-888e4766ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_outputs[dataset_name] = cleaning_function(raw_outputs[dataset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602a25eb-6789-4f37-b8b4-75e26757e303",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[dataset_name] = pd.DataFrame({\n",
    "    'correct_answer': dt['train']['correct_answer'],\n",
    "    'answer': clean_outputs[dataset_name],\n",
    "})\n",
    "\n",
    "dfs[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2134e67f-0cf8-454a-b739-d3c5a785e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[dataset_name]['valid'] = dfs[dataset_name].answer.str.lower().isin(['a', 'b', 'c', 'd', 'e'])\n",
    "dfs[dataset_name]['correct'] = dfs[dataset_name].answer.str.lower() == dfs[dataset_name].correct_answer.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c916dcf6-716e-4e06-9617-10e8c4813620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct answers vs valid answers\n",
    "metrics[dataset_name] = (dfs[dataset_name]['valid'].mean().item(), dfs[dataset_name].correct.mean().item())\n",
    "metrics[dataset_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2712a078-6e9e-4785-90ce-d3f907d6bbb5",
   "metadata": {},
   "source": [
    "### CTK Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f004e194-a868-4c21-b8b1-b9bd716b0a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'ctkfacts'\n",
    "\n",
    "dt = load_dataset(DATASETS[dataset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6440244c-8a05-4fb1-beac-fcf6a37d9c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = message_function(MESSAGES, dt['train']['user_prompt'], dt['train']['system_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2940b19-5b82-46b0-9e68-28171d23ab6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pipe(messages[:5], return_full_text=False, max_new_tokens=MAX_NEW_TOKENS[dataset_name])\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a6858b-32fa-4b0c-a932-425d3d5501e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_outputs[dataset_name] = pipe(messages, return_full_text=False, max_new_tokens=MAX_NEW_TOKENS[dataset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ac54a-0557-426f-83ec-a41b950189ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_outputs[dataset_name] = cleaning_function(raw_outputs[dataset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729c55f3-d9a2-403a-9243-e6865c8f09cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[dataset_name] = pd.DataFrame({\n",
    "    'correct_answer': dt['train']['label'],\n",
    "    'answer': clean_outputs[dataset_name],\n",
    "})\n",
    "\n",
    "dfs[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419fd5ca-7ea5-420d-8c70-4c0ed31620f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[dataset_name]['valid'] = dfs[dataset_name].answer.isin(['0', '1', '2'])\n",
    "dfs[dataset_name]['correct'] = dfs[dataset_name].answer == dfs[dataset_name].correct_answer.apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaaec1a-aff7-4f63-8eab-05e018fca34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct answers vs valid answers\n",
    "metrics[dataset_name] = (dfs[dataset_name]['valid'].mean().item(), dfs[dataset_name].correct.mean().item())\n",
    "metrics[dataset_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645c17bd-b18e-4c23-bd96-f83ce2579b9a",
   "metadata": {},
   "source": [
    "## Metrics & Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cedfd63-be09-4942-9329-cd6bcf668000",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3212d735-6a98-4b5a-b75d-a477e2c143f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NAME = f\"{MODEL.split('/')[1]}_{DATA_SIZE}_{MESSAGES}_{PIPELINE_TYPE}\"\n",
    "RUN_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23224a2d-7bd3-496d-a0e8-a955950ab61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "objects_to_save = {\n",
    "    'model': MODEL,\n",
    "    'datasets': DATASETS,\n",
    "    'raw_outputs': raw_outputs,\n",
    "    'dfs': dfs,\n",
    "    'metrics': metrics\n",
    "}\n",
    "\n",
    "if OUTPUT_DIR:\n",
    "    with gzip.open(f\"{OUTPUT_DIR}/{RUN_NAME}.pkl.gz\", \"wb\") as file:\n",
    "        pickle.dump(objects_to_save, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bbaa96-2d98-4414-9efa-d305452d1c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with gzip.open(f\"{OUTPUT_DIR}/{RUN_NAME}.pkl.gz\", \"rb\") as file:\n",
    "#    loaded_objects = pickle.load(file)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python [conda env:experimental]",
   "language": "python",
   "name": "conda-env-experimental-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

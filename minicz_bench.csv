model,average_accuracy,agree_accuracy,czech_news_accuracy,klokanek_accuracy,ctkfacts_accuracy,average_validity
claude-3-5-sonnet-20240620,0.7124999999999999,0.88,0.81,0.445,0.715,0.99875
gpt-4o,0.6537499999999999,0.735,0.83,0.355,0.695,0.99625
unsloth/Mistral-Large-Instruct-2407-bnb-4bit,0.63625,0.635,0.82,0.365,0.725,1.0
gemini-1.5-flash-latest,0.6174999999999999,0.625,0.815,0.34,0.69,0.9937499999999999
Qwen/Qwen2.5-32B-Instruct,0.61375,0.65,0.785,0.4,0.62,1.0
unsloth/Qwen2.5-72B-Instruct-bnb-4bit,0.6112500000000001,0.55,0.785,0.435,0.675,1.0
google/gemma-2-27b-it,0.6,0.57,0.8,0.315,0.715,1.0
unsloth/Meta-Llama-3.1-70B-Instruct-bnb-4bit,0.5962500000000001,0.555,0.79,0.315,0.725,0.99875
fsaudm/Meta-Llama-3.1-70B-Instruct-NF4,0.595,0.545,0.805,0.32,0.71,0.99375
unsloth/Llama-3.1-Nemotron-70B-Instruct-bnb-4bit,0.5775,0.535,0.77,0.285,0.72,0.9975
claude-3-haiku-20240307,0.57625,0.575,0.795,0.285,0.65,1.0
gpt-4o-mini,0.5750000000000001,0.585,0.805,0.31,0.6,0.995
speakleash/Bielik-11B-v2.3-Instruct,0.57375,0.55,0.805,0.245,0.695,1.0
AMead10/c4ai-command-r-08-2024-awq,0.5674999999999999,0.47,0.83,0.28,0.69,1.0
mistralai/Mistral-Small-Instruct-2409,0.5599999999999999,0.405,0.825,0.275,0.735,1.0
unsloth/c4ai-command-r-08-2024-bnb-4bit,0.5599999999999999,0.455,0.765,0.305,0.715,1.0
CohereForAI/aya-expanse-32b,0.5575,0.495,0.785,0.28,0.67,0.9975
google/gemma-2-9b-it,0.5325,0.485,0.785,0.25,0.61,1.0
Qwen/Qwen2.5-7B-Instruct,0.52625,0.37,0.715,0.31,0.71,1.0
CohereForAI/aya-23-35B,0.52125,0.485,0.76,0.235,0.605,0.99875
NousResearch/Hermes-3-Llama-3.1-8B,0.51875,0.435,0.695,0.26,0.685,1.0
CohereForAI/aya-expanse-8b,0.515,0.485,0.76,0.23,0.585,1.0
mistralai/Mixtral-8x7B-Instruct-v0.1,0.5125,0.295,0.76,0.265,0.73,0.985
mistralai/Ministral-8B-Instruct-2410,0.50875,0.39,0.685,0.285,0.675,1.0
meta-llama/Llama-3.1-8B-Instruct,0.495,0.43,0.75,0.2,0.6,1.0
mistralai/Mistral-Nemo-Instruct-2407,0.49375,0.31,0.715,0.265,0.685,1.0
google/gemma-2-2b-it,0.48624999999999996,0.43,0.64,0.305,0.57,1.0
mistralai/Mistral-7B-Instruct-v0.3,0.47750000000000004,0.285,0.675,0.265,0.685,1.0
meta-llama/Meta-Llama-3-8B-Instruct,0.475,0.31,0.715,0.29,0.585,1.0
CohereForAI/aya-23-8B,0.4625,0.24,0.71,0.28,0.62,1.0
meta-llama/Llama-3.2-3B-Instruct,0.41875000000000007,0.325,0.505,0.32,0.525,1.0
Qwen/Qwen2.5-3B-Instruct,0.40874999999999995,0.385,0.41,0.27,0.57,1.0
microsoft/Phi-3.5-mini-instruct,0.38625,0.185,0.57,0.24,0.55,1.0
Qwen/Qwen2.5-1.5B-Instruct,0.335,0.375,0.27,0.27,0.425,1.0
ibm-granite/granite-3.0-8b-instruct,0.33125,0.23,0.53,0.24,0.325,0.995
microsoft/Phi-3-mini-4k-instruct,0.3175,0.09,0.535,0.185,0.46,0.83
microsoft/Phi-3-mini-128k-instruct,0.31125,0.13,0.62,0.0,0.495,0.6625
mistralai/Mistral-7B-Instruct-v0.1,0.30000000000000004,0.195,0.445,0.02,0.54,0.77125
ibm-granite/granite-3.0-2b-instruct,0.21000000000000002,0.225,0.2,0.075,0.34,0.84375
microsoft/Phi-3-medium-4k-instruct,0.135,0.315,0.0,0.225,0.0,0.41500000000000004
microsoft/Phi-3-medium-128k-instruct,0.08625,0.195,0.0,0.15,0.0,0.23875000000000002
meta-llama/Llama-3.2-1B-Instruct,0.0525,0.005,0.03,0.175,0.0,0.17625
HuggingFaceTB/SmolLM-1.7B-Instruct,0.01625,0.0,0.0,0.065,0.0,0.05
